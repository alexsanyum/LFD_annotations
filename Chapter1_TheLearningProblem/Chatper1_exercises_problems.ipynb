{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: The Learning problem\n",
    "\n",
    "This chapter is dedicated to introduce the basics concepts of learning. \n",
    "\n",
    "In a learning problem, it is sais that exist a certain function $f$ that maps perfectly $X$ to $Y$. Means, \n",
    "\n",
    "$f: X \\to Y$. \n",
    "\n",
    "But we do not know this function, but we have examples of those maps. In a fancy way $X$ is call input space, and $Y$ the target space. As example of $Y$ space, take as example a binary categorical result. Imagine you are a doctor, and need to decide, with many information, weather or not the patient is sick. In this example, $Y = \\{-1,+1\\}$ where -1 denote False stament, or the patient is not sick, and +1 denotes True staments, the patient is actually sick. \n",
    "Take in count that for this categorical example, -1,+1 could be replace with other labels, but we like to give numbers in AI. \n",
    "\n",
    "\n",
    "Now, $f$ is the ideal function, and 99.9% of the times, unknow. However, we may have examples of this maps, means, examples of $\\textbf{x} \\in X$ with their $y \\in Y$, that means, we have examples of $(\\textbf{x}, y)$ points. Note here, that $y$ represented **the correct** answer of $\\textbf{x}$. When we have this information, as we see further, we are in **supervised** case. \n",
    "\n",
    "Why supervised?\n",
    "\n",
    "At the begining, the word cause me some confusion, because I though that supervised means that we supervise the traning process XD. But, that is not the case, supervised comes from the fact that **somebody** (HUMAN) supervised $\\textbf(x)$ and annotate the correct $y$. The process is supervised, because someone supervised the data giving they a label, or value.\n",
    "\n",
    "\n",
    "Another fancy name. The whole set of examples set of  $(\\textbf{x}, y)$ points is denoted with $D$ in the book. In the fancy way (N denotes the number of examples we have)\n",
    "\n",
    "$D = \\{(\\textbf{x}_{1},y_{1}),(\\textbf{x}_{2},y_{2}),...,(\\textbf{x}_{N},y_{N})\\}$\n",
    "\n",
    "Take in count that, because they are examples of the real (and unknown) function $f$, each $y_i = f(\\textbf{x}_{i})$ for $i = 1,2,...,N$\n",
    "\n",
    "The larning problems claims that \n",
    "\n",
    "There is a learning algorithm that use $D$ to **pick up** a formula $g: X \\to Y$ that aproximate to $f$. BUT, this $g$ does not come from the nowhere, it belongs to a set of fourmulas $H$  that contain all candidate formulas to the learning problem. $H$ has a fancy name in this book, hypothesis set. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1\n",
    "\n",
    "Express each of the following tasks in the framework of learning from data by specifying the input space $X$, output space $Y$, target function $f: X \\to Y$, and the specifics of the data set that we will learn from\n",
    "\n",
    "**(a)** Medical diagnosis: A patient walks in with a medical history and some symptoms, and you want to identify the problem.\n",
    "\n",
    "$X$: medical history, symptoms.\n",
    "$Y$: a set of possible diagnosis, i.e {fever, diabetes, ...}.\n",
    "$f$: a function that map the patient history with their symptons to a diagnosis.\n",
    "$D$: records, from the past, of diagnosticated sickness with patient information.\n",
    "\n",
    "**(b)** Handwritten digit recognition (for example postal zip code recognition for mail sorting).\n",
    "\n",
    "$X$: images of digit handwritten \\\n",
    "$Y$: a set of all digits {0 to 9}. \\\n",
    "$f$: a function that takes an digit image, and return the correct digit. \\\n",
    "$D$: set of digit images with a label that denote de correct digit. \n",
    "\n",
    "**(c)** Determinig if an email is spam or not.\n",
    "\n",
    "$X$: mail subject(title), who send it \\\n",
    "$Y$: a set of {spam, not spam} \\\n",
    "$f$: a function that given a mail, return if it is spam or not. \\\n",
    "$D$: set of labeled mails specifying if they are spam or not.  \n",
    "\n",
    "**(d)** Predicting how an electric load varies with price, temperature, and  day of the week.\n",
    "\n",
    "\n",
    "**(e)** A problem of interest to you for which there is no analytic solution, but you have data from which to construct an empirical solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It start introducing a basic hypethesis function h, as\n",
    "\n",
    "$h(\\textbf{x}) = sign({\\textbf{w}}^{T}\\textbf{x})$\n",
    "\n",
    "Where $\\textbf{x}$ denotes a vector of features, \\textbf{w} a vector of weights of those features. Basically, the function is a linear combination of both weigths and features, and return the sign (positive or negative) of the sum. \n",
    "\n",
    "In learning problem, we want to get an ideal function $h$ that the book denote it with $g$. To do that given the $\\textbf{x}$ input, need to fund a way to get the best vector $\\textbf{w}$ that aproximates $g$ to the real function $f$ that is unknown with a basic learning model *perceptron learning algorithm* (PLA). Before that, introduce some "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
